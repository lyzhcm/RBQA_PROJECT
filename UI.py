#ui
import streamlit as st
import pandas as pd
from datetime import datetime
from file_registry import FileRegistry
from knowledge_base_manager import (
    delete_file,
    restore_file,
    toggle_file_tag,
    semantic_analysis,
    add_file_to_knowledge_base
)
from ai_service import ask_ai
import vector_store as db_op

def _process_files_callback():
    """
    å½“æ–‡ä»¶ä¸Šä¼ æ—¶è°ƒç”¨çš„å›è°ƒå‡½æ•°ã€‚
    å®ƒåœ¨ä¸‹ä¸€æ¬¡UIé‡æ–°æ¸²æŸ“ä¹‹å‰å¤„ç†æ–‡ä»¶ï¼Œç¡®ä¿çŠ¶æ€åŒæ­¥ã€‚
    """
    # é€šè¿‡keyä»ä¼šè¯çŠ¶æ€è·å–ä¸Šä¼ çš„æ–‡ä»¶
    uploaded_files = st.session_state.get("knowledge_file_uploader")
    if not uploaded_files:
        return

    # åœ¨å¤„ç†æ–‡ä»¶æ—¶æ˜¾ç¤ºåŠ è½½æŒ‡ç¤ºå™¨
    with st.spinner("æ­£åœ¨å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶..."):
        for file in uploaded_files:
            add_file_to_knowledge_base(file)

# çŸ¥è¯†åº“ç®¡ç†ç•Œé¢
def knowledge_base_section():
    st.header("ğŸ“š çŸ¥è¯†åº“æ„å»ºä¸ç®¡ç†")

    # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    # ä½¿ç”¨on_changeå›è°ƒæ¥å¤„ç†æ–‡ä»¶ï¼Œè€Œä¸æ˜¯åœ¨UIæ¸²æŸ“æµç¨‹ä¸­å¤„ç†
    st.file_uploader(
        "ä¸Šä¼ çŸ¥è¯†æ–‡æ¡£ (æ”¯æŒå¤šç§æ ¼å¼)",
        type=["txt", "pdf", "docx", "pptx", "md"],
        accept_multiple_files=True,
        key="knowledge_file_uploader",  # ä¸ºå°éƒ¨ä»¶æä¾›ä¸€ä¸ªå”¯ä¸€çš„key
        on_change=_process_files_callback # ç»‘å®šå›è°ƒå‡½æ•°
    )

    # æ˜¾ç¤ºä¸Šä¼ æ–‡ä»¶åˆ—è¡¨
    st.subheader("æ–‡æ¡£ç®¡ç†")
    st.info("ä½¿ç”¨ä»¥ä¸‹è¡¨æ ¼ç®¡ç†æ‚¨çš„æ–‡æ¡£ï¼š")

    files_df = pd.DataFrame([
        {
            "ID": f["id"],
            "æ–‡ä»¶å": f["name"],
            "ç±»å‹": f["type"],
            "å¤§å°": f"{len(f['content']) // 1024} KB" if f.get('content') else "æœªçŸ¥",
            "ä¸Šä¼ æ—¶é—´": f["upload_time"],
            "æ ‡è®°": ", ".join(f.get("tags", [])) if "tags" in f else "",
        }
        for f in st.session_state.uploaded_files
    ])

    # å¦‚æœæ²¡æœ‰ä»»ä½•æ–‡ä»¶æ˜¾ç¤ºæç¤ºä¿¡æ¯
    if files_df.empty:
        st.info("æš‚æ— æ–‡æ¡£ï¼Œè¯·ä¸Šä¼ æ–‡æ¡£")
    else:
        # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
        st.dataframe(files_df.set_index('ID'), use_container_width=True)

        # æ–‡ä»¶ç®¡ç†åŠŸèƒ½åŒº
        with st.expander("ğŸ“Œ æ–‡ä»¶æ“ä½œ", expanded=True):
            col1, col2, col3, col4 = st.columns([0.4, 0.2, 0.2, 0.2])

            # æ–‡ä»¶é€‰æ‹©
            file_ids = list(files_df["ID"])
            selected_file_id = col1.selectbox("é€‰æ‹©æ–‡ä»¶", file_ids, format_func=lambda id: 
                files_df.loc[files_df["ID"] == id, "æ–‡ä»¶å"].values[0])

            # æ ‡è®°ç®¡ç†
            tags = ["é‡è¦", "å¾…å®¡æ ¸", "å­˜æ¡£", "å‚è€ƒ"]
            selected_tag = col2.selectbox("æ·»åŠ /ç§»é™¤æ ‡è®°", tags)

            # æŒ‰é’®æ“ä½œ
            if col3.button("åº”ç”¨æ ‡è®°", key="tag_btn", use_container_width=True):
                toggle_file_tag(selected_file_id, selected_tag)
                st.rerun()

            if col4.button("åˆ é™¤æ–‡ä»¶", key="delete_btn", type="primary", use_container_width=True):
                delete_file(selected_file_id)
                st.rerun()

        # å›æ”¶ç«™ç®¡ç†
        if st.session_state.deleted_files:
            with st.expander("ğŸ—‘ï¸ å›æ”¶ç«™ç®¡ç†", expanded=True):
                deleted_df = pd.DataFrame([
                    {
                        "ID": f["id"],
                        "æ–‡ä»¶å": f["name"],
                        "ç±»å‹": f["type"],
                        "åˆ é™¤æ—¶é—´": f["deleted_time"],
                    }
                    for f in st.session_state.deleted_files
                ])

                st.dataframe(deleted_df.set_index('ID'), use_container_width=True)

                restore_id = st.selectbox("é€‰æ‹©è¦æ¢å¤çš„æ–‡ä»¶", deleted_df["ID"], format_func=lambda id: 
                    deleted_df.loc[deleted_df["ID"] == id, "æ–‡ä»¶å"].values[0])

                if st.button("æ¢å¤æ–‡ä»¶", use_container_width=True):
                    if restore_file(restore_id):
                        st.success(f"æ–‡ä»¶å·²æ¢å¤")
                        st.rerun()
                    else:
                        st.error("æ¢å¤æ–‡ä»¶å¤±è´¥")

                if st.button("æ¸…ç©ºå›æ”¶ç«™", type="primary", use_container_width=True):
                    st.session_state.deleted_files = []
                    st.success("å›æ”¶ç«™å·²æ¸…ç©º")
                    st.rerun()

        # æŸ¥çœ‹çŸ¥è¯†åº“å†…å®¹
        with st.container():  # æ›¿æ¢å¤–å±‚ Expander
            st.subheader("ğŸ” æŸ¥çœ‹çŸ¥è¯†åº“å†…å®¹")
            if not st.session_state.knowledge_base:
                st.info("çŸ¥è¯†åº“ä¸ºç©ºï¼Œè¯·å…ˆä¸Šä¼ æ–‡æ¡£ã€‚")
            else:
                source_files = set(kb['source_id'] for kb in st.session_state.knowledge_base)
                for src_id in list(source_files)[:3]:  # æœ€å¤šæ˜¾ç¤ºå‰3ä¸ªæ–‡ä»¶çš„å†…å®¹
                    source_name = next(
                        kb['source'] for kb in st.session_state.knowledge_base if kb['source_id'] == src_id)
                    st.subheader(f"æ¥æº: {source_name}")
                    for kb in [k for k in st.session_state.knowledge_base if k['source_id'] == src_id][:3]:
                        with st.expander(f"çŸ¥è¯†ç‰‡æ®µ {kb['content'][:30]}...", expanded=False):
                            st.markdown(kb["content"])
                    st.divider()
                if len(source_files) > 3:
                    st.info(f"å·²æ˜¾ç¤º3ä¸ªæ–‡ä»¶çš„å†…å®¹ï¼Œå…±{len(source_files)}ä¸ªæ–‡ä»¶")

# é—®ç­”ç•Œé¢ï¼ˆç»“åˆè¯­ä¹‰ç†è§£å’ŒDeepSeekï¼‰
def qa_interface():
    st.header("ğŸ’¬ğŸ’¬ æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")

    # --- Part 1: Display the entire conversation history from session state ---
    # ä¸ºé˜²æ­¢æ—§çš„åŸºäºå­—ç¬¦ä¸²çš„ä¼šè¯çŠ¶æ€å¼•å‘é”™è¯¯ï¼Œè¿›è¡Œä¸€æ¬¡æ€§è¿ç§»
    if "conversation" in st.session_state and st.session_state.conversation and isinstance(st.session_state.conversation[0], str):
         st.session_state.conversation = []

    for message in st.session_state.conversation:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            # å¦‚æœæ˜¯AIåŠ©æ‰‹çš„æ¶ˆæ¯ï¼Œå¹¶ä¸”åŒ…å«é™„åŠ ä¿¡æ¯ï¼Œåˆ™æ˜¾ç¤ºå®ƒä»¬
            if message["role"] == "assistant":
                if "references" in message and message["references"]:
                    with st.expander("ğŸ“šğŸ“š å‚è€ƒæ–‡æ¡£", expanded=False):
                        for i, doc in enumerate(message["references"], 1):
                            source = getattr(doc, "metadata", {}).get("source", f"æ–‡æ¡£{i}")
                            content = getattr(doc, "page_content", str(doc))[:200] + "..."
                            st.caption(f"ã€æ–‡çŒ®{i}ã€‘{source}")
                            st.text(content)
                if "analysis" in message and message["analysis"]:
                    with st.expander("ğŸ”ğŸ” è¯­ä¹‰åˆ†æè¯¦æƒ…", expanded=False):
                        st.json(message["analysis"])

    # --- Part 2: Process new input and add to history ---
    if question := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        # å°†ç”¨æˆ·æ¶ˆæ¯é™„åŠ åˆ°å†å²è®°å½•
        st.session_state.conversation.append({"role": "user", "content": question})

        # --- æ‰€æœ‰å¤„ç†é€»è¾‘åœ¨æ­¤å¼€å§‹ ---
        with st.spinner("æ­£åœ¨åˆ†æå’Œç”Ÿæˆå›ç­”..."):
            # 1. ä¸Šä¸‹æ–‡åˆ†æ
            context_analysis = ""
            similarity = 0.0  # é»˜è®¤å€¼
            # æŸ¥æ‰¾ä¸Šä¸€ä¸ªç”¨æˆ·é—®é¢˜è¿›è¡Œæ¯”è¾ƒ
            last_user_message = next((msg for msg in reversed(st.session_state.conversation[:-1]) if msg['role'] == 'user'), None)
            if last_user_message:
                last_question = last_user_message['content']
                model = st.session_state.get("embedding_model")
                if model:
                    from numpy import dot
                    from numpy.linalg import norm
                    last_embedding = model.encode([last_question])[0]
                    current_embedding = model.encode([question])[0]
                    similarity = dot(last_embedding, current_embedding)/(norm(last_embedding)*norm(current_embedding))
                    
                    if similarity > 0.7:
                        context_analysis = f"\næ³¨æ„ï¼šè¿™ä¸ªé—®é¢˜ä¸ä¸Šä¸€ä¸ªé—®é¢˜é«˜åº¦ç›¸å…³ï¼ˆç›¸ä¼¼åº¦{similarity:.2f}ï¼‰ï¼Œè¯·è€ƒè™‘ä¸Šä¸‹æ–‡å›ç­”ã€‚"
                        last_assistant_message = next((msg for msg in reversed(st.session_state.conversation[:-1]) if msg['role'] == 'assistant'), None)
                        last_answer = last_assistant_message['content'] if last_assistant_message else ""
                        context_analysis += f"\nä¸Šä¸€ä¸ªé—®é¢˜: {last_question}\nä¸Šä¸€ä¸ªå›ç­”: {last_answer}"
                else:
                    st.warning("åµŒå…¥æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡Œä¸Šä¸‹æ–‡å…³è”åˆ†æã€‚")

            # 2. è¯­ä¹‰åˆ†æå¤„ç†
            semantic_info = semantic_analysis(question)
            intent = semantic_info["intent"]
            entities = semantic_info["entities"]

            # 3. å‘é‡æ£€ç´¢
            docs = db_op.search_db(question, k=3)

            # 4. æ„å»ºç§‘å­¦é—®ç­”æç¤ºè¯
            context = "\n".join([
                f"ã€æ–‡çŒ® {i + 1}ã€‘{doc.metadata['source']}\n{doc.page_content}\n"
                for i, doc in enumerate(docs)
            ])
            
            history_for_prompt = '\n'.join([f"{msg['role']}: {msg['content']}" for msg in st.session_state.conversation[-7:-1]])

            prompt = f"""æ ¹æ®ä»¥ä¸‹æ–‡çŒ®å†…å®¹å›ç­”é—®é¢˜ï¼š
{context}
é—®é¢˜ï¼š{question}
{context_analysis}
è¦æ±‚ï¼š
1. å›ç­”éœ€å¼•ç”¨æ–‡çŒ®ï¼ˆä¾‹ï¼šã€æ–‡çŒ®1ã€‘ï¼‰
2. ä¿æŒå­¦æœ¯ä¸¥è°¨æ€§
3. å¦‚æ— ç›¸å…³ä¿¡æ¯è¯·è¯´æ˜
4. é—®é¢˜æ„å›¾ï¼š{intent}
5. å…³é”®å®ä½“ï¼š{', '.join(entities)}
6. è€ƒè™‘ä»¥ä¸‹å¯¹è¯å†å²ï¼š
{history_for_prompt}
å›ç­”ï¼š"""

            # 5. è°ƒç”¨AIç”Ÿæˆå›ç­”
            answer = ask_ai(prompt)

            # 6. å‡†å¤‡ç”¨äºæ˜¾ç¤ºçš„é™„åŠ ä¿¡æ¯
            analysis_details = {
                "é—®é¢˜æ„å›¾": intent,
                "è¯†åˆ«å®ä½“": entities,
                "åŒ¹é…ç‰‡æ®µæ•°": len(docs),
                "ä¸Šä¸‹æ–‡å…³è”åº¦": f"{similarity:.2f}" if similarity > 0 else "æ— ",
                "æç¤ºè¯": prompt[:500] + "..." if len(prompt) > 500 else prompt
            }

            # 7. å°†åŒ…å«æ‰€æœ‰ä¿¡æ¯çš„åŠ©æ‰‹æ¶ˆæ¯é™„åŠ åˆ°å†å²è®°å½•
            st.session_state.conversation.append({
                "role": "assistant",
                "content": answer,
                "references": docs,
                "analysis": analysis_details
            })
        
        # 8. Rerun ä»¥æ˜¾ç¤ºå†å²è®°å½•ä¸­çš„æ–°æ¶ˆæ¯
        st.rerun()